{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://<host>:<port>\")\n",
    "\n",
    "Churn_train_df = pd.read_csv('../Data/Raw-Data/train.csv')\n",
    "Churn_validation_df = pd.read_csv('../Data/Raw-Data/test.csv')\n",
    "\n",
    "overweight_threshold = 25\n",
    "Churn_train_df['BMI'] = Churn_train_df['Weight'] / (Churn_train_df['Height'] ** 2)\n",
    "Churn_train_df['Overweight'] = (Churn_train_df['BMI'] > overweight_threshold).astype(int)\n",
    "Churn_train_df = Churn_train_df.drop(columns='BMI')\n",
    "\n",
    "Churn_validation_df['BMI'] = Churn_validation_df['Weight'] / (Churn_validation_df['Height'] ** 2)\n",
    "Churn_validation_df['Overweight'] = (Churn_validation_df['BMI'] > overweight_threshold).astype(int)\n",
    "Churn_validation_df = Churn_validation_df.drop(columns='BMI')\n",
    "\n",
    "columns_to_ordinal_encode=Churn_train_df.select_dtypes(exclude=[np.number]).columns\n",
    "columns_to_ordinal_encode=columns_to_ordinal_encode.drop('NObeyesdad')\n",
    "\n",
    "\n",
    "\n",
    "# Apply Ordinal Encoder to specified columns\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "Churn_train_df[columns_to_ordinal_encode] = ordinal_encoder.fit_transform(Churn_train_df[columns_to_ordinal_encode])\n",
    "\n",
    "# Apply Label Encoder to target column\n",
    "label_encoder = LabelEncoder()\n",
    "target_column = 'NObeyesdad'\n",
    "Churn_train_df[target_column] = label_encoder.fit_transform(Churn_train_df[target_column])\n",
    "\n",
    "Churn_validation_df[columns_to_ordinal_encode] = ordinal_encoder.transform(Churn_validation_df[columns_to_ordinal_encode])\n",
    "\n",
    "\n",
    "X = Churn_train_df.drop(columns=[target_column])\n",
    "y = Churn_train_df[target_column]\n",
    "\n",
    "X_val = Churn_validation_df\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score,accuracy_score\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(columns='id'), y, test_size=0.25, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 10,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 42\n",
    "}\n",
    "# Creating XGBClassifier instance\n",
    "XGBClassifier_Model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "XGBClassifier_Model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "accuracy = XGBClassifier_Model.score(X_test, y_test)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = XGBClassifier_Model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_test, y_pred,average='micro')\n",
    "recall = recall_score(y_test, y_pred,average='micro')\n",
    "f1 = f1_score(y_test, y_pred,average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification = classification_report(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n {classification}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion}\")\n",
    "\n",
    "\n",
    "y_val_pred = XGBClassifier_Model.predict(X_val.drop(columns='id'))\n",
    "\n",
    "y_pred_original = pd.DataFrame(label_encoder.inverse_transform(y_val_pred),columns=['NObeyesdad'])\n",
    "\n",
    "submission_df=pd.concat([X_val['id'],y_pred_original],axis=1)\n",
    "\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://<host>:<port>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Churn_train_df = pd.read_csv('../Data/Raw-Data/train.csv')\n",
    "Churn_validation_df = pd.read_csv('../Data/Raw-Data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "overweight_threshold = 25\n",
    "Churn_train_df['BMI'] = Churn_train_df['Weight'] / (Churn_train_df['Height'] ** 2)\n",
    "Churn_train_df['Overweight'] = (Churn_train_df['BMI'] > overweight_threshold).astype(int)\n",
    "Churn_train_df = Churn_train_df.drop(columns='BMI')\n",
    "\n",
    "Churn_validation_df['BMI'] = Churn_validation_df['Weight'] / (Churn_validation_df['Height'] ** 2)\n",
    "Churn_validation_df['Overweight'] = (Churn_validation_df['BMI'] > overweight_threshold).astype(int)\n",
    "Churn_validation_df = Churn_validation_df.drop(columns='BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn_train_df['Total charge'] =  Churn_train_df['Total day charge'] + Churn_train_df['Total eve charge'] + Churn_train_df['Total night charge'] + Churn_train_df['Total intl charge']\n",
    "# Churn_validation_df['Total charge'] = Churn_validation_df['Total day charge'] + Churn_validation_df['Total eve charge'] + Churn_validation_df['Total night charge'] + Churn_validation_df['Total intl charge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn_train_df = Churn_train_df.drop(columns=['Total intl charge', 'Total night charge', 'Total day charge', 'Total eve charge'])\n",
    "# Churn_validation_df = Churn_validation_df.drop(columns=['Total intl charge', 'Total night charge', 'Total day charge', 'Total eve charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Overweight_Level_II', 'Normal_Weight', 'Insufficient_Weight',\n",
       "       'Obesity_Type_III', 'Obesity_Type_II', 'Overweight_Level_I',\n",
       "       'Obesity_Type_I'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Churn_train_df['NObeyesdad'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>10378.500000</td>\n",
       "      <td>5992.462780</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5189.250000</td>\n",
       "      <td>10378.500000</td>\n",
       "      <td>15567.750000</td>\n",
       "      <td>20757.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>23.841804</td>\n",
       "      <td>5.688072</td>\n",
       "      <td>14.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.815416</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>1.700245</td>\n",
       "      <td>0.087312</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.631856</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.762887</td>\n",
       "      <td>1.975663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>87.887768</td>\n",
       "      <td>26.379443</td>\n",
       "      <td>39.00</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>84.064875</td>\n",
       "      <td>111.600553</td>\n",
       "      <td>165.057269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FCVC</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>2.445908</td>\n",
       "      <td>0.533218</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.393837</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCP</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>2.761332</td>\n",
       "      <td>0.705375</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH2O</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>2.029418</td>\n",
       "      <td>0.608467</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.792022</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.549617</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAF</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>0.981747</td>\n",
       "      <td>0.838302</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.587406</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUE</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>0.616756</td>\n",
       "      <td>0.602113</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight</th>\n",
       "      <td>20758.0</td>\n",
       "      <td>0.714134</td>\n",
       "      <td>0.451837</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count          mean          std    min          25%  \\\n",
       "id          20758.0  10378.500000  5992.462780   0.00  5189.250000   \n",
       "Age         20758.0     23.841804     5.688072  14.00    20.000000   \n",
       "Height      20758.0      1.700245     0.087312   1.45     1.631856   \n",
       "Weight      20758.0     87.887768    26.379443  39.00    66.000000   \n",
       "FCVC        20758.0      2.445908     0.533218   1.00     2.000000   \n",
       "NCP         20758.0      2.761332     0.705375   1.00     3.000000   \n",
       "CH2O        20758.0      2.029418     0.608467   1.00     1.792022   \n",
       "FAF         20758.0      0.981747     0.838302   0.00     0.008013   \n",
       "TUE         20758.0      0.616756     0.602113   0.00     0.000000   \n",
       "Overweight  20758.0      0.714134     0.451837   0.00     0.000000   \n",
       "\n",
       "                     50%           75%           max  \n",
       "id          10378.500000  15567.750000  20757.000000  \n",
       "Age            22.815416     26.000000     61.000000  \n",
       "Height          1.700000      1.762887      1.975663  \n",
       "Weight         84.064875    111.600553    165.057269  \n",
       "FCVC            2.393837      3.000000      3.000000  \n",
       "NCP             3.000000      3.000000      4.000000  \n",
       "CH2O            2.000000      2.549617      3.000000  \n",
       "FAF             1.000000      1.587406      3.000000  \n",
       "TUE             0.573887      1.000000      2.000000  \n",
       "Overweight      1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "Churn_train_df.select_dtypes(include=[np.number]).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>20758</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>10422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <td>20758</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>17014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAVC</th>\n",
       "      <td>20758</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>18982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAEC</th>\n",
       "      <td>20758</td>\n",
       "      <td>4</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>17529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOKE</th>\n",
       "      <td>20758</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>20513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCC</th>\n",
       "      <td>20758</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>20071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALC</th>\n",
       "      <td>20758</td>\n",
       "      <td>3</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>15066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTRANS</th>\n",
       "      <td>20758</td>\n",
       "      <td>5</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>16687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NObeyesdad</th>\n",
       "      <td>20758</td>\n",
       "      <td>7</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "      <td>4046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count unique                    top   freq\n",
       "Gender                          20758      2                 Female  10422\n",
       "family_history_with_overweight  20758      2                    yes  17014\n",
       "FAVC                            20758      2                    yes  18982\n",
       "CAEC                            20758      4              Sometimes  17529\n",
       "SMOKE                           20758      2                     no  20513\n",
       "SCC                             20758      2                     no  20071\n",
       "CALC                            20758      3              Sometimes  15066\n",
       "MTRANS                          20758      5  Public_Transportation  16687\n",
       "NObeyesdad                      20758      7       Obesity_Type_III   4046"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Churn_train_df.select_dtypes(exclude=[np.number]).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_ordinal_encode=Churn_train_df.select_dtypes(exclude=[np.number]).columns\n",
    "columns_to_ordinal_encode=columns_to_ordinal_encode.drop('NObeyesdad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "# Apply Ordinal Encoder to specified columns\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "Churn_train_df[columns_to_ordinal_encode] = ordinal_encoder.fit_transform(Churn_train_df[columns_to_ordinal_encode])\n",
    "\n",
    "# Apply Label Encoder to target column\n",
    "label_encoder = LabelEncoder()\n",
    "target_column = 'NObeyesdad'\n",
    "Churn_train_df[target_column] = label_encoder.fit_transform(Churn_train_df[target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Churn_validation_df[columns_to_ordinal_encode] = ordinal_encoder.transform(Churn_validation_df[columns_to_ordinal_encode])\n",
    "\n",
    "# Churn_validation_df[target_column] = label_encoder.transform(Churn_validation_df[target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Churn_train_df.drop(columns=[target_column])\n",
    "y = Churn_train_df[target_column]\n",
    "\n",
    "X_val = Churn_validation_df\n",
    "# y_val = Churn_validation_df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2044\n",
      "[LightGBM] [Info] Number of data points in the train set: 15568, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -2.112351\n",
      "[LightGBM] [Info] Start training from score -1.911439\n",
      "[LightGBM] [Info] Start training from score -1.945461\n",
      "[LightGBM] [Info] Start training from score -1.860211\n",
      "[LightGBM] [Info] Start training from score -1.636985\n",
      "[LightGBM] [Info] Start training from score -2.148581\n",
      "[LightGBM] [Info] Start training from score -2.108641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Precision: 0.905587668593449\n",
      "Recall: 0.905587668593449\n",
      "F1 Score: 0.905587668593449\n",
      "Accuracy: 0.905587668593449\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       640\n",
      "           1       0.88      0.89      0.89       780\n",
      "           2       0.90      0.87      0.88       685\n",
      "           3       0.97      0.98      0.97       825\n",
      "           4       1.00      1.00      1.00      1017\n",
      "           5       0.78      0.78      0.78       611\n",
      "           6       0.80      0.81      0.81       632\n",
      "\n",
      "    accuracy                           0.91      5190\n",
      "   macro avg       0.90      0.89      0.90      5190\n",
      "weighted avg       0.91      0.91      0.91      5190\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 593   43    0    0    0    3    1]\n",
      " [  26  698    0    0    0   48    8]\n",
      " [   2    0  594   20    2   20   47]\n",
      " [   0    0   12  809    2    0    2]\n",
      " [   0    0    1    1 1014    1    0]\n",
      " [   4   43   14    0    0  478   72]\n",
      " [   0   10   42    6    0   60  514]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score,accuracy_score\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(columns='id'), y, test_size=0.25, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 10,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state': 42\n",
    "}\n",
    "# Creating XGBClassifier instance\n",
    "XGBClassifier_Model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "XGBClassifier_Model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "accuracy = XGBClassifier_Model.score(X_test, y_test)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = XGBClassifier_Model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_test, y_pred,average='micro')\n",
    "recall = recall_score(y_test, y_pred,average='micro')\n",
    "f1 = f1_score(y_test, y_pred,average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification = classification_report(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n {classification}\")\n",
    "print(f\"Confusion Matrix:\\n {confusion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aizaz/anaconda3/envs/py310/lib/python3.10/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'tracking-quickstart' already exists. Creating a new version of this model...\n",
      "2024/02/16 12:29:06 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: tracking-quickstart, version 2\n",
      "Created version '2' of model 'tracking-quickstart'.\n"
     ]
    }
   ],
   "source": [
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow Quickstart\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    # mlflow.log_metric(\"classification\", classification)\n",
    "    # mlflow.log_metric(\"confusion\", confusion)\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Basic LR model for iris data\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, XGBClassifier_Model.predict(X_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=XGBClassifier_Model,\n",
    "        artifact_path=\"iris_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"tracking-quickstart\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = XGBClassifier_Model.predict(X_val.drop(columns='id'))\n",
    "\n",
    "y_pred_original = pd.DataFrame(label_encoder.inverse_transform(y_val_pred),columns=['NObeyesdad'])\n",
    "\n",
    "submission_df=pd.concat([X_val['id'],y_pred_original],axis=1)\n",
    "\n",
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
